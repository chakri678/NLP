{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUSe9Wu7WMIC"
      },
      "source": [
        "# The aim of the project is to build a fake news classifier using Natural Language Processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "amFMndl4WMID"
      },
      "outputs": [],
      "source": [
        "#import the necessary libraries\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RW61DuLVWMIE"
      },
      "outputs": [],
      "source": [
        "#Loading dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "83o0rewsWMIF"
      },
      "outputs": [],
      "source": [
        "#count the number of rows and columns in the dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4knFRCg2WMIF"
      },
      "outputs": [],
      "source": [
        "#increasing the width of the the columns\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NM6EauM2WMIF"
      },
      "outputs": [],
      "source": [
        "#Print the the number of data points belonging to each categories\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgSvrihiWMIG"
      },
      "outputs": [],
      "source": [
        "#Count the number of null values present in the dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove the null values from the dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WMcUY9BoZQGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check no null values present in the dataset?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Kuy_G7RZQI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reset the index of the given series\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J_C92HyEZQLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text cleaning\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sQbqtkIvZQNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove all alpha numeric letters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MU814r4tZQQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert all strings to lowercase \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y35PfH25ZiTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove all '\\n' in the string and replace it with a space\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cja0rhU-ZiWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove all non-ascii characters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gieMGBexZiYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply all the lambda functions wrote previously through .map on the comments column\n",
        "df['text'] = df['text'].map(alphanumeric).map(punc_lower).map(remove_n).map(remove_non_ascii)\n",
        "df['text']"
      ],
      "metadata": {
        "id": "jLnqByhIZibU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing stop words\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MvSKTTf_Zidr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing stop words and stemming the text\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(0, len(df)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', df['text'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "metadata": {
        "id": "JFXrRdwYZigL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataframe\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PiE8wWzCZ7jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making train and test data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qasJAGEZZ7lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tfidf vectorizer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AvN0e4IpZ7n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count vectorizer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JX2mbb7SZ7qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes model on tfidf\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rRk4lkcZZ7wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes model on Count Vectorized\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jTear8eOZQSy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}